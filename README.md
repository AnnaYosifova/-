ВАРИАНТ 8

Задание 1. 
Для модели с n_all = 60 ошибки на обучающей и тестовой выборках составиили 0.28 и 0.71 соответсвенно. Наименьшее значение MSE достигается при 28 степенях свободы, а ошибки на обучающей и тестовой выборках составили 0.60057 и 0.51634 соответсвенно.

Задание 2. 
Для модели с n_all = 300 ошибки на обучающей и тестовой выборках составиили 0.79 и 1.39 соответсвенно. Наименьшее значение MSE достигается при 11 степенях свободы, а ошибки на обучающей и тестовой выборках составили 0.95476 и 1.14492 соответсвенно.
Для модели с n_all = 250 ошибки на обучающей и тестовой выборках составиили 0.77 и 1.11 соответсвенно. Наименьшее значение MSE достигается при 12 степенях свободы, а ошибки на обучающей и тестовой выборках составили 0.948923 и 0.983036 соответсвенно.
Для модели с n_all = 200 ошибки на обучающей и тестовой выборках составиили 0.78 и 0.89 соответсвенно. Наименьшее значение MSE достигается при 13 степенях свободы, а ошибки на обучающей и тестовой выборках составили 1.001225 и 0.814976 соответсвенно.

Вывод:
При уменьшении значения n_all ошибки на тестовой выборке уменьшаются. Лучшей моделью является 3ья при n_all = 200, т.к. в ней ошибка на тестовой выборке минимальна. 
Чем больше наблюдений, через которые прошёл сплайн, тем точнее модель. Это говорит о переобучении. Лучшую модель следуют выбирать по минимуму на кривой MSE на тестовой выборке.
При слишком большом числе степеней свободы (как в задании 1 с 28 степенями свободы) происходит переобучение.
